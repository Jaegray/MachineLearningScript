# -*- coding: utf-8 -*-
"""gradientdescentlearningscript.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vfr4IfiK1GdaraLZRbkrQkPYN0ROTNss

# Gradient Descent Learning Script for Machine Learning 
### by Jae Gray

# 1

#### Starting from initial value use learning rate .5 report f1 and f2 values in 10 iterations.
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# for f1
cur_x = 1 #designated a starting value
rate = 0.5 # Learning rate
precision_value = 0.000001 
previous_size = 1
max_iters = 10 
iters = 0 
df = lambda x: -x+5 #Gradient of the function

# creating a loop
while previous_size > precision_value and iters < max_iters:
    prev_x = cur_x 
    cur_x = cur_x - rate * df(prev_x) 
    previous_size = abs(cur_x - prev_x) 
    iters = iters+1 
    print("Iteration",iters,"\nX value is",cur_x)

#for f2
cur_x = 1 
rate = 0.5 # Learning rate
precision_value = 0.000001 
previous_size = 1 
max_iters = 10 # iterations
iters = 0 
df = lambda x: -2*(y+4) #Gradient the function

while previous_step_size > precision_value and iters < max_iters:
    prev_x = cur_x 
    cur_x = cur_x - rate * df(prev_x) 
    previous_step_size = abs(cur_x - prev_x) 
    iters = iters+1 
    print("Iteration",iters,"\nX value is",cur_x)

"""#### Following step 2 please change your code to try to search minimums for f1 and f2. Explain the motivation of your changes and the final minimum values. """

# for f1
cur_x = 1 
rate = 0.5 # Learning rate
precision_value = 0.000001 
previous_size = 1 
max_iters = 500
iters = 0 
df = lambda x: -x+5 

while previous_step_size > precision_value and iters < max_iters:
    prev_x = cur_x 
    cur_x = cur_x - rate * df(prev_x) 
    previous_size = abs(cur_x - prev_x) 
    iters = iters+1 
    print("Iteration",iters,"\nX value is",cur_x) 
    
print("The local minimum is at", cur_x)

# for f2
cur_x = 3 
rate = 0.01 
precision_value = 0.000001 
previous_size = 1 
max_iters = 10000 
iters = 0 
df = lambda x: -2*(y+4)

while previous_step_size > precision_value and iters < max_iters:
    prev_x = cur_x 
    cur_x = cur_x - rate * df(prev_x) 
    previous_size = abs(cur_x - prev_x) 
    iters = iters+1 
    print("Iteration",iters,"\nX value is",cur_x) 
    
print("The local minimum is at", cur_x)

"""#### The code was changed to perform more iterations. So when the precision value is set, this will control when the algorithm stops. For f1, the optimal was at x=1. For f2, the optimal was at

# 2

#### Class 1 and class 2 text files in canvas contain 2-dimensional instances in two classes, C1 and C2. 
#### Randomly select 80% instances from class1.txt and class2.txt to train a perceptron classifier. Use the classifier to classify remaining 20% instances in each class. Report the classification accuracy of the perceptron classifier on the 20% test instances.
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from google.colab import files 
uploaded = files.upload()

import io 
dataset = pd.read_csv(io.BytesIO(uploaded['Class1.txt']))
print("dataset")
print(dataset.shape)

from google.colab import files
uploaded = files.upload()

dataset2 = pd.read_csv(io.BytesIO(uploaded['Class2.txt']))
print("dataset2")
print(dataset.shape)

# adding labels to data
positivelabel=1
negativelabel=-1
Threshold=(positivelabel+negativelabel)/2
dataset.insert(dataset.shape[1],'label',positivelabel)
dataset2.insert(dataset2.shape[1],'label',negativelabel)
# combining the datasets
datasetscombined = dataset.append(dataset2)
print(datasetscombined.shape)
datasetscombined.head()

#plotting the data as given
colors=["red","black","blue","green"]
plt.scatter(datasetscombined.iloc[:,0],datasetscombined.iloc[:,1],color=[colors[idx+1] for idx in datasetscombined.iloc[:,2]])
# the output is not linearly separable.

# dividing the data into training
# and test data
from sklearn.utils import shuffle
datasetscombined_rand=shuffle(datasetscombined)
features,labels=datasetscombined_rand.iloc[:,0:-1],datasetscombined_rand.loc[:,['label']]
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(features,labels, test_size=.4, random_state=42)
# now converting data into a matrix
x_train_m=np.asmatrix(x_train, dtype = 'float64')
x_test_m=np.asmatrix(x_test, dtype = 'float64')
x_train_m=np.asmatrix(y_train, dtype = 'float64')
y_test_m=np.asmatrix(y_test, dtype = 'float64')

def GradientDescentLearning(features, labels, max_iter, learning_rate, err_threshold, test_features, test_labels):
    totalSquaredErrTest_
    totalSquaredErrTest_ = []
    accuracy_= []
    epoch=0
    err=9999.0
    while (epoch<max_iter) and (err>err_threshold):
        misclassified = 0
        deltaw=[0]*(features.shape[1]+1)
        for i, x in enumerate(features):
            x = np.insert(x,0,1)

            v = np.dot(w, x.transpose())
            
            diff = learning_rate*(labels[i] - v)
            deltaw=deltaw+diff*x
        
        #update weights
        #print(deltaw)
        w=w+deltaw
        
        # Calculating training error
        this_err=0
        for i, x in enumerate(features):
            x = np.insert(x,0,1)
            v = np.dot(w, x.transpose())
            this_err=this_err+(labels[i] - v)*(labels[i] - v)
        this_err=np.ndarray.item(this_err) 
        this_err=this_err/2.0
        #mean squared error
        err=this_err/features.shape[0]        
        totalSquaredErr_.append(err)
        
        # calculating test error using new weights
        this_err=0
        for i, x in enumerate(test_features):
            x = np.insert(x,0,1)
            v = np.dot(w, x.transpose())
            this_err=this_err+(test_labels[i] - v)*(test_labels[i] - v)
        this_err=np.ndarray.item(this_err) 
        this_err=this_err/2.0
        totalSquaredErrTest_.append(this_err/test_features.shape[0])
        # testing accuracy
        this_err=0
        for i, x in enumerate(test_features):
            x = np.insert(x,0,1)
            v = np.dot(w, x.transpose())
            if(((v-T)>=0 and test_labels[i]==negLabel) or ((v-T)<0 and test_labels[i]==posLabel)):
                this_err=this_err+1
        this_err=float(this_err) 
        this_err=this_err/test_features.shape[0]
        accuracy_.append(1-this_err)        
        #next epoch
        epoch=epoch+1
    return (w, totalSquaredErr_, totalSquaredErrTest_, accuracy_)

"""#### Revise the Delta learning rule in the Gradient Descent Learning Notebook to learn from the same 80% of training samples."""

import random
def Delta(features, labels, max_iter, learning_rate, err_threshold):
  w = np.random.rand(features.shape[1]+1)-0.5

  totalSquaredErr_ = []
  epoch=0
  err=9999.0
  while (epoch<max_iter) and (err>err_threshold):
    misclassified = 0
    deltaw=[0]*(features.shape[1]+1)
    i=random.randrange(features.shape[0])
    x=features[i,]
    x = np.insert(x,0,1)

    v = np.dot(w, x.transpose())

    diff = learning_rate*(labels[i] - v)
    deltaw=deltaw+diff*x

    w=w+deltaw

    this_err=0
    for i, x in enumerate(features):
      x = np.insert(x,0,1)
      v = np.dot(w, x.transpose())
      this_err=this_err+(labels[i] - v)*(labels[i] - v)
    this_err=np.asscalar(this_err)
    this_err=this_err/2.0
    totalSquaredErr_.append(this_err)
    #MSE
    err=this_err/features.shape[0]
    epoch=epoch+1
  return (w, totalSquaredErr_)

max_iter = 200 #across 200 iterations
eta=1.0/x_train.shape[0]
print("The learning rate is: %.5f" % eta)
err_threshold=0.05
w, misclassified, testError, accuracy= GradientDescentLearning(x_train_m, y_train_m, max_iter, eta, err_threshold,x_test_m,y_test_m)
print(misclassified[0:10])
print(testError[0:10])
print(accuracy[0:10])